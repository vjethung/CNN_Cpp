{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Of2kDjB4O7R",
        "outputId": "b0eb62da-3352-495e-c95d-e10f93251ebb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensor reshaped (3,5,5):\n",
            "tensor([[[[156., 155., 156., 158., 158.],\n",
            "          [153., 154., 157., 159., 159.],\n",
            "          [149., 151., 155., 158., 159.],\n",
            "          [146., 146., 149., 153., 158.],\n",
            "          [145., 143., 143., 148., 158.]],\n",
            "\n",
            "         [[167., 166., 167., 169., 169.],\n",
            "          [164., 165., 168., 170., 170.],\n",
            "          [160., 162., 166., 169., 170.],\n",
            "          [156., 156., 159., 163., 168.],\n",
            "          [155., 153., 153., 158., 168.]],\n",
            "\n",
            "         [[163., 162., 163., 165., 165.],\n",
            "          [160., 161., 164., 166., 166.],\n",
            "          [156., 158., 162., 165., 166.],\n",
            "          [155., 155., 158., 162., 167.],\n",
            "          [154., 152., 152., 157., 167.]]]])\n",
            "Shape: torch.Size([1, 3, 5, 5])\n",
            "\n",
            "After proj_conv2:\n",
            "tensor([[[[-26., 465., 465., 474., 652.],\n",
            "          [294., 786., 797., 811., 670.],\n",
            "          [290., 775., 783., 799., 658.],\n",
            "          [292., 770., 772., 781., 644.],\n",
            "          [158., 327., 323., 318., 334.]]]], grad_fn=<ConvolutionBackward0>)\n",
            "Shape: torch.Size([1, 1, 5, 5])\n",
            "\n",
            "After proj_conv2.weight:\n",
            "tensor([[[[-1., -1.,  1.],\n",
            "          [ 0.,  1., -1.],\n",
            "          [ 0.,  1.,  1.]],\n",
            "\n",
            "         [[ 1.,  0.,  0.],\n",
            "          [ 1., -1., -1.],\n",
            "          [ 1.,  0., -1.]],\n",
            "\n",
            "         [[ 0.,  1.,  1.],\n",
            "          [ 0.,  1.,  0.],\n",
            "          [ 1., -1.,  1.]]]])\n",
            "Shape: torch.Size([1, 3, 3, 3])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def check_tensor_processing():\n",
        "    flat_input = np.array([\n",
        "        156.0, 155.0, 156.0, 158.0, 158.0,\n",
        "        153.0, 154.0, 157.0, 159.0, 159.0,\n",
        "        149.0, 151.0, 155.0, 158.0, 159.0,\n",
        "        146.0, 146.0, 149.0, 153.0, 158.0,\n",
        "        145.0, 143.0, 143.0, 148.0, 158.0,\n",
        "        167.0, 166.0, 167.0, 169.0, 169.0,\n",
        "        164.0, 165.0, 168.0, 170.0, 170.0,\n",
        "        160.0, 162.0, 166.0, 169.0, 170.0,\n",
        "        156.0, 156.0, 159.0, 163.0, 168.0,\n",
        "        155.0, 153.0, 153.0, 158.0, 168.0,\n",
        "        163.0, 162.0, 163.0, 165.0, 165.0,\n",
        "        160.0, 161.0, 164.0, 166.0, 166.0,\n",
        "        156.0, 158.0, 162.0, 165.0, 166.0,\n",
        "        155.0, 155.0, 158.0, 162.0, 167.0,\n",
        "        154.0, 152.0, 152.0, 157.0, 167.0\n",
        "    ])\n",
        "\n",
        "    tensor = torch.tensor(flat_input, dtype=torch.float32).reshape(1, 3, 5, 5)\n",
        "    print(f\"Tensor reshaped (3,5,5):\\n{tensor}\\nShape: {tensor.shape}\\n\")\n",
        "\n",
        "\n",
        "    weights_tensor = torch.tensor(\n",
        "        [[[[-1., -1.,  1.],\n",
        "          [ 0.,  1., -1.],\n",
        "          [ 0.,  1.,  1.]],\n",
        "         [[ 1.,  0.,  0.],\n",
        "          [ 1., -1., -1.],\n",
        "          [ 1.,  0., -1.]],\n",
        "         [[ 0.,  1.,  1.],\n",
        "          [ 0.,  1.,  0.],\n",
        "          [ 1., -1.,  1.]]]]\n",
        "    )\n",
        "\n",
        "    bias = torch.tensor([0.0])\n",
        "\n",
        "    # Tạo filter\n",
        "    proj_conv2 = nn.Conv2d(in_channels=3, out_channels=1, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "    # Cập nhật trọng số của Conv2d\n",
        "    with torch.no_grad():\n",
        "        proj_conv2.weight.data.copy_(weights_tensor)\n",
        "\n",
        "    # Cập nhật bias của Conv2d\n",
        "    with torch.no_grad():\n",
        "        proj_conv2.bias.data.copy_(bias)\n",
        "\n",
        "    # Kiểm tra kết quả sau khi áp dụng Convolution\n",
        "    output = proj_conv2(tensor)\n",
        "\n",
        "    print(f\"After proj_conv2:\\n{output}\\nShape: {output.shape}\\n\")\n",
        "    print(f\"After proj_conv2.weight:\\n{proj_conv2.weight.data}\\nShape: {proj_conv2.weight.data.shape}\\n\")\n",
        "\n",
        "check_tensor_processing()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjHPihd35YAX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
